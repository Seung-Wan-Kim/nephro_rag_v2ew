""import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
import os

# -------------------- ì„¤ì • --------------------
# ë²¡í„° DB ê²½ë¡œ ìë™ ì„ íƒ í•¨ìˆ˜
def get_vector_path_from_question(question):
    keywords = {
        "aki": ["aki", "ê¸‰ì„±ì‹ ì†ìƒ"],
        "ckd": ["ckd", "ë§Œì„±ì‹ ì§ˆí™˜", "ë§Œì„±ì½©íŒ¥ë³‘"],
        "ns": ["nephrotic", "ì‹ ì¦í›„êµ°"],
        "gn": ["glomerulonephritis", "ì‚¬êµ¬ì²´ì‹ ì—¼"],
        "electrolyte": ["electrolyte", "ì „í•´ì§ˆ"]
    }
    for folder, keys in keywords.items():
        for key in keys:
            if key.lower() in question.lower():
                return f"vector_store_{folder}/"
    return "vector_store_aki/"  # ê¸°ë³¸ê°’

# -------------------- Streamlit UI --------------------
st.set_page_config(page_title="Nephrology RAG System", layout="wide")
st.title("ğŸ§  ì‹ ì¥ë‚´ê³¼ ì§„ë‹¨ ì§€ì› ì‹œìŠ¤í…œ")

# ìˆ˜ì¹˜ ì…ë ¥ ì¹¼ëŸ¼ êµ¬ì„±
st.subheader("1. í˜ˆì•¡ ê²€ì‚¬ ìˆ˜ì¹˜ ì…ë ¥")
cols = st.columns(4)

input_labels = [
    "BUN", "Creatinine", "B/C ratio", "eGFR", "Na", "K", "Cl", "CO2", "Ca", "IP",
    "Hb", "PTH", "Vitamin D", "ALP", "LDH", "Lactate", "Albumin", "Proteinuria", "CRP", "Glucose"
]

user_inputs = {}
for i, label in enumerate(input_labels):
    with cols[i % 4]:
        user_inputs[label] = st.text_input(f"{label}")

# ê²°ê³¼ í™•ì¸ ë²„íŠ¼ 1 (ìˆ˜ì¹˜ ê¸°ë°˜ ì§„ë‹¨ìš©)
if st.button("ìˆ˜ì¹˜ ê¸°ë°˜ ê²°ê³¼ í™•ì¸"):
    st.markdown("ğŸ‘‰ ì´ ê¸°ëŠ¥ì€ í–¥í›„ êµ¬í˜„ë  ì˜ˆì •ì…ë‹ˆë‹¤. í˜„ì¬ëŠ” ìì—°ì–´ ì§ˆë¬¸ë§Œ ì§€ì›ë©ë‹ˆë‹¤.")

# ìì—°ì–´ ì§ˆë¬¸
st.subheader("2. ìì—°ì–´ ì§ˆë¬¸")
query = st.text_area("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ê¸‰ì„±ì‹ ì†ìƒì˜ ì •ì˜ëŠ”?")

# ê²°ê³¼ í™•ì¸ ë²„íŠ¼ 2 (RAG)
if st.button("ìì—°ì–´ ê¸°ë°˜ ì§ˆì˜ ê²°ê³¼ í™•ì¸") and query:
    # ë²¡í„° ê²½ë¡œ ì¶”ì¶œ
    vector_path = get_vector_path_from_question(query)

    # ë²¡í„° íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not (os.path.exists(os.path.join(vector_path, "index.faiss")) and os.path.exists(os.path.join(vector_path, "index.pkl"))):
        st.error(f"í•´ë‹¹ ì§ˆë³‘êµ°ì— ëŒ€í•œ ë²¡í„° ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {vector_path}")
    else:
        # ì„ë² ë”© ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
        embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-nli")

        # ë²¡í„° DB ë¡œë“œ
        try:
            db = FAISS.load_local(vector_path, embedding_model, allow_dangerous_deserialization=True)
        except ValueError as e:
            st.error(f"FAISS ë¡œë”© ì˜¤ë¥˜: {str(e)}")
            st.stop()

        # QA ì²´ì¸ ìƒì„±
        qa = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0.3), chain_type="stuff", retriever=db.as_retriever())

        # ë‹µë³€ ìƒì„±
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            result = qa.run(query)
        st.markdown("#### ğŸ“˜ ë‹µë³€")
        st.write(result)

# ì°¸ê³ 
st.markdown("---")
st.markdown("ğŸ“ *ë³¸ ì‹œìŠ¤í…œì€ 5ê°œ ì£¼ìš” ì‹ ì¥ë‚´ê³¼ ì§ˆí™˜êµ°(AKI, CKD, NS, GN, Electrolyte)ì˜ ë¬¸ì„œ ì„ë² ë”© ê¸°ë°˜ RAG ì‹œìŠ¤í…œì…ë‹ˆë‹¤.*")
